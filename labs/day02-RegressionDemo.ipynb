{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 135 day02: Basics of Regression Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "* Practice loading data from CSV files and manipulating that data with Pandas and NumPy\n",
    "* Try out sklearn's linear regression on a dataset with 1-dim. features and many features\n",
    "* Try out sklearn's k-nearest neighbor regression on a dataset with 1-dim. features and many features\n",
    "* Try out comparing models using mean squared error as a performance metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What to do\n",
    "\n",
    "Download the *abalone* dataset from our course starter-code repo here:\n",
    "\n",
    "* Dataset CSV files: https://github.com/tufts-ml-courses/cs135-26s-assignments/tree/main/labs/data_abalone\n",
    "* Dataset README: https://github.com/tufts-ml-courses/cs135-26s-assignments/tree/main/labs/data_abalone/README.md\n",
    "\n",
    "In class (or later at home), work your way through this notebook. \n",
    "\n",
    "Each \"part\" has a structure like this:\n",
    "\n",
    "* First, some prefilled content so you can learn how to do basic ML operations with sklearn.\n",
    "* Second, some simple exercises to try to figure things out yourself\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "* [Part 1: Linear Regression with 1-dim. features](#part1)\n",
    "* * Real Task: Regression of 'rings' given 'length' using abalone dataset\n",
    "* * Exercise 1a: Reproduce the `predict` method\n",
    "* [Part 2: Linear Regression with 3-dim. features](#part2)\n",
    "* * Real Task: Regression of 'rings' given 'length', 'height', 'weight'\n",
    "* * Exercise 2a: Reproduce the `predict` method\n",
    "* * Exercise 2b: Compare mean squared error on training set with model from part 1\n",
    "* [Part 3: K-nearest neighbor regression](#part3)\n",
    "* * Real Task: Regression of 'rings' given 'length'\n",
    "* * Exercise 3a: How does training set error vary with number of neighbors?\n",
    "* * Exercise 3b: Repeat using all available features (not just length)\n",
    "* * Exercise 3c: Reproduce the `predict` method for k-NN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotting libraries\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-v0_8') # pretty matplotlib plots\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set('notebook', style='whitegrid', font_scale=1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running in cloud on Google colab, be sure to acquire the required dataset\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\") and not os.path.exists('data_abalone'):\n",
    "    !git clone https://github.com/tufts-ml-courses/cs135-26s-assignments.git\n",
    "    os.chdir(os.path.join('cs135-26s-assignments', 'labs'))\n",
    "    \n",
    "if not os.path.exists('data_abalone'):\n",
    "    raise ValueError(\"Need to run this script within a valid checkout of the cs135 repo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Simple Linear Regression with 1-dim. features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal: Predict 'rings' outcome given 'length' of abalone\n",
    "\n",
    "We'll do this in a few easy steps below:\n",
    "\n",
    "1) Load in 'x' training data, the 'length' of each abalone\n",
    "\n",
    "2) Load in 'y' training data, the 'rings' count of each abalone\n",
    "\n",
    "3) Train a linear regression model by calling 'fit'\n",
    "\n",
    "4) Make predictions using this model by calling 'predict'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load in 'x', the inputs for our regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first 5 lines of this CSV:\n",
    "\n",
    "with open('data_abalone/x_train.csv', 'r') as f:\n",
    "    for line in f.readlines()[:5]:\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data into a Panda's dataframe called 'x_df'\n",
    "x_df = pd.read_csv('data_abalone/x_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first 3 rows\n",
    "x_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary stats\n",
    "x_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how to access column names\n",
    "for col in x_df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from pandas DataFrame to a numpy array with N rows and F columns\n",
    "x_NF = x_df.values.copy()\n",
    "\n",
    "print(type(x_NF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_NF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_NF.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert only the 'length' column into a numpy array\n",
    "\n",
    "xlength_N1 = x_df.loc[:, ['length_mm']].values.copy()\n",
    "\n",
    "print(xlength_N1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now we've got our input! Time for step 2...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load in 'y', the output of our regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.read_csv('data_abalone/y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first 6 rows\n",
    "y_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary stats\n",
    "y_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_N1 = y_df.loc[:, ['rings']].values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_N1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Fit a linear regression model, using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the regression \"object\"\n",
    "# The variable 'lin_regr' here is an \"instance\" of the LinearRegression class\n",
    "\n",
    "lin_regr = sklearn.linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the documentation:\n",
    "\n",
    "<https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression>\n",
    "\n",
    "\n",
    "Any constructed regressor in sklearn (like 'lin_regr') has two useful methods:\n",
    "* 'fit' method\n",
    "* 'predict' method (only works after 'fit' is called)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'fit' method will *TRAIN* the model\n",
    "\n",
    "Practically, this method call will \n",
    "\n",
    "1) Estimate weight coefficients $w$ and bias/intercept $b$ to minimize mean squared error\n",
    "\n",
    "2) Updates internal state of the object with these estimated values.\n",
    "\n",
    "For linear regression specifically:\n",
    "\n",
    "* an attribute called `coef_` holds the weights\n",
    "* an attribute called `intercept_` holds the intercept value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_regr.fit(xlength_N1, y_N1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What changed after calling fit?\n",
    "\n",
    "The *internal state* of the object was updated.\n",
    "\n",
    "We can see the *internal state* via the \"coef\" attribute (the *slope* parameter) and the \"intercept\" attribute (aka *bias* parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_regr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_regr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you know what an object can do??\n",
    "\n",
    "Pro tip: in an active Jupyter notebook, you can use *tab completion* to interactively inspect an object\n",
    "\n",
    "Just type \"lin_regr.\" and then press the <tab> key.\n",
    "    \n",
    "You should see a pop up menu that let's you see what methods and attributes are accessible, like this:\n",
    "    \n",
    "![Image of tab completion](https://www.cs.tufts.edu/comp/135/2020f/images/day02_jupyter_object_inspect_on_tab.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it here, add \".\" plus <tab>\n",
    "lin_regr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Make predictions using this trained linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare to evaluate predictions at several possible length values:\n",
    "G = 7\n",
    "x_grid_G = np.asarray([0.0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5])\n",
    "print(x_grid_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn this into a G x 1 2-dim array, since sklearn *always* expects feature input to be 2-dim\n",
    "x_grid_G1 = x_grid_G[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we call `predict`, which, when given 2-dim array with shape (G,F) of features, will return a 2-dim array of size (G, 1) of *predicted values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_lin_G1 = lin_regr.predict(x_grid_G1)\n",
    "print(yhat_lin_G1)\n",
    "print(yhat_lin_G1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Plot the *predicted* values side by side with the observed training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xlength_N1, y_N1, 'k.', alpha=0.2)\n",
    "plt.plot(x_grid_G, yhat_lin_G1, 'bs-', linewidth=3);\n",
    "plt.xlabel('length (mm)'); plt.ylabel('ring count');\n",
    "plt.title(\"Linear Regression using 'length' feature\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Calculate the mean squared error on the observed training data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train_N1 = lin_regr.predict(xlength_N1)\n",
    "sklearn.metrics.mean_squared_error(y_N1, yhat_train_N1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Linear Regression with multiple features\n",
    "\n",
    "### Goal: Predict 'rings' outcome given 'length', 'height', and 'weight' of abalone\n",
    "\n",
    "How would we do if we wanted to predict 'rings' given not just length, but also height and weight?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data\n",
    "\n",
    "We now want our features array to have shape: (n_examples, 3)\n",
    "\n",
    "Since 3 would let us use length and height and weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in x_df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab relevant columns only, convert to a numeric array\n",
    "x_N3 = x_df.loc[:, ['length_mm', 'height_mm', 'whole_weight_g']].values.copy()\n",
    "print(type(x_N3))\n",
    "print(x_N3.dtype)\n",
    "print(x_N3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct the model as an sklearn regressor object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_regr_3dim = sklearn.linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_regr_3dim.fit(x_N3, y_N1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: what are the learned weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: what is the learned intercept?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Activity: Feature Selection\n",
    "\n",
    "With the person (or people) next to you, try to find the combination of 3 features that gives the best performance. Later we'll learn why this is not the best way to perform feature selection, but for now we'll consider one set of features as being better if it achieves lower mean squared error on the training data. \n",
    "\n",
    "Have you and your partner (or partners) each choose a different strategy for trying to find the best combination:\n",
    "\n",
    "1. First find the best 1-feature model, then \"lock-in\" that feature and look for the second feature that best complements that first feature, then lock in 2 features and look for a third. \n",
    "2. Exhaustively trying all possible combinations of 3 features. \n",
    "3. Calculate the correlation between each feature and $y$ using `sklearn.feature_selection.r_regression` and choose the 3 most correlated features.\n",
    "4. Vibe it out\n",
    "5. Another strategy you think of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with your group, consider the following questions:\n",
    "\n",
    "1. Which strategy found the best performance? How much better was it than the other method(s)?\n",
    "2. What is the worst-case time complexity (Big-O) of each strategy you tried, given in terms of the number of instances N and the number of features F?\n",
    "3. Which strategy would you choose if you had 100 features? What about 1 million? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: K-nearest Neighbor Regression with 1-dim features\n",
    "\n",
    "### Goal: Try out sklearn's built-in nearest neighbor regressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1nn_regr = sklearn.neighbors.KNeighborsRegressor(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "k1nn_regr.fit(xlength_N1, y_N1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare to evaluate predictions at several possible length values:\n",
    "G = 21\n",
    "x_grid_G = np.linspace(0, 1.5, G)\n",
    "print(x_grid_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_grid_G1 = np.reshape(x_grid_G, (G, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the same grid of x input values\n",
    "yhat_k1nn_G1 = k1nn_regr.predict(x_grid_G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xlength_N1, y_N1, 'k.', alpha=0.5)\n",
    "plt.plot(x_grid_G, yhat_k1nn_G1, 'bs-', linewidth=3);\n",
    "plt.xlabel('length (mm)'); plt.ylabel('ring count');\n",
    "plt.title('K=1 Nearest Neighbor Regression');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retry with 5 nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k5nn_regr = sklearn.neighbors.KNeighborsRegressor(\n",
    "    n_neighbors=5, algorithm='brute', metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "k5nn_regr.fit(xlength_N1, y_N1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the same grid of x input values\n",
    "yhat_k5nn_G1 = k5nn_regr.predict(x_grid_G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xlength_N1, y_N1, 'k.', alpha=0.2)\n",
    "plt.plot(x_grid_G1, yhat_k5nn_G1, 'bs-', linewidth=3);\n",
    "plt.xlabel('length (mm)'); plt.ylabel('ring count');\n",
    "plt.title('K=5 Nearest Neighbor Regression');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retry with 100 nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k100nn_regr = sklearn.neighbors.KNeighborsRegressor(\n",
    "    n_neighbors=100, algorithm='brute', metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "k100nn_regr.fit(xlength_N1, y_N1);\n",
    "\n",
    "# Make predictions on the same grid of x input values\n",
    "yhat_k100_G1 = k100nn_regr.predict(x_grid_G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xlength_N1, y_N1, 'k.', alpha=0.2)\n",
    "plt.plot(x_grid_G1, yhat_k100_G1, 'bs-', linewidth=3);\n",
    "plt.xlabel('length (mm)'); plt.ylabel('ring count');\n",
    "plt.title('K=100 Nearest Neighbor Regression');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises for Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion Question 3(i): What happens when you call `fit` for a k-NN regressor? \n",
    "\n",
    "What (if anything) gets estimated or computed?\n",
    "What (if anything) gets updated as an attribute of the regressor object?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion Question 3(ii): k-NN should have a piecewise constant predictions.... why do the plots above look different?\n",
    "\n",
    "*Hint:* Try a finer grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion Question 3(iii): Does the predicted function look smoother or more jagged as K increases? Why does this make sense given how this classifier works?\n",
    "\n",
    "*Hint*: What should happen in the limit as K -> N?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3a (code): Make a plot of the mean squared error on the *training* set as a function of the number of neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3b (code): Repeat part 3 using *all* available features (not just length). Does your performance improve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Yourself\n",
    "\n",
    "### Exercise 3c (code): Can you write a function to reproduce what happens when you call `predict()` with kNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs135_26s_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
