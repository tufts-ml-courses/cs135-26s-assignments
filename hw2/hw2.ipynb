{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2 : Cross-Validation and  Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration and imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "import sklearn.preprocessing\n",
    "import sklearn.pipeline\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "#This sets the default style for all figures. \n",
    "sns.set('notebook', font_scale=1.25, style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to adjust your data directory to point towards the auto data. Please do not adjust the random seed for the version of your results you turn in.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 12345 \n",
    "\n",
    "DATA_DIR = 'data_auto/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Here we provide some functions you may find useful for your analysis. You are not **required** to use these helper functions, but you may find them useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_2d_arr_from_csv(fname, include_header=False):\n",
    "    x = np.loadtxt(os.path.join(DATA_DIR, fname), delimiter=',', skiprows=1)\n",
    "    assert x.ndim == 2\n",
    "    if include_header:\n",
    "        header_cols = np.loadtxt(os.path.join(DATA_DIR, fname), delimiter=',', dtype=str)[0].tolist()\n",
    "        return x, header_cols\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def load_1d_arr_from_csv(fname):\n",
    "    x = np.loadtxt(os.path.join(DATA_DIR, fname), delimiter=',', skiprows=1)\n",
    "    if x.ndim == 1:\n",
    "        return x\n",
    "    else:\n",
    "        raise ValueError(\"Not 1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions can then be used as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['horsepower', 'weight', 'cylinders', 'displacement']\n",
      "[[ 115. 2595.    6.  173.]\n",
      " [ 180. 4380.    8.  350.]\n",
      " [ 150. 4457.    8.  318.]\n",
      " [ 105. 3897.    6.  250.]\n",
      " [ 193. 4732.    8.  304.]]\n",
      "[[28.8]\n",
      " [16.5]\n",
      " [14. ]\n",
      " [16. ]\n",
      " [ 9. ]]\n"
     ]
    }
   ],
   "source": [
    "x_tr_MF, xcolnames_F = load_2d_arr_from_csv('x_train.csv', include_header=True)\n",
    "x_va_NF = load_2d_arr_from_csv('x_valid.csv')\n",
    "x_te_PF = load_2d_arr_from_csv('x_test.csv')\n",
    "\n",
    "y_tr_M = load_1d_arr_from_csv('y_train.csv')\n",
    "y_va_N = load_1d_arr_from_csv('y_valid.csv')\n",
    "y_te_P = load_1d_arr_from_csv('y_test.csv')\n",
    "\n",
    "print(xcolnames_F)\n",
    "print(x_tr_MF[:5])\n",
    "print(y_tr_M[:5,np.newaxis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_and_valid_error_vs_hyper(\n",
    "        hyper_list, err_tr_list=None, err_va_list=None,\n",
    "        ymax=40,\n",
    "        leg_loc='upper right',\n",
    "        xlabel='polynomial degree',\n",
    "        ylabel='RMSE'):\n",
    "    if err_va_list is not None:\n",
    "        plt.plot(hyper_list, err_va_list, 'rs-', label='valid');\n",
    "    if err_tr_list is not None:\n",
    "        plt.plot(hyper_list, err_tr_list, 'bd:', label='train');\n",
    "    plt.ylim([0, ymax]);\n",
    "    plt.legend(loc=leg_loc);\n",
    "    plt.xlabel(xlabel);\n",
    "    plt.ylabel(ylabel);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a regression pipeline\n",
    "\n",
    "### Sanitizing output\n",
    "You should sanitize any model's predictions to help ensure the predicted values that are physically plausible. \n",
    "We are predicting MPG, which should \n",
    "* (1) always be positive, and\n",
    "* (2) will probably never exceed 120% of the largest value we see in train data\n",
    "\n",
    "Predictions should be sanitized before being used to calculate errors or select best-performing models for your report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_MAX = 60.0 # The max MPG is about 48 in the training set\n",
    "\n",
    "def sanitize(yhat_N):\n",
    "    yhat_N = np.maximum(yhat_N, 0)\n",
    "    yhat_N = np.minimum(yhat_N, Y_MAX)\n",
    "    return yhat_N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating multiple pipelines\n",
    "\n",
    "This function returns a scikit-learn `pipeline` that of the specified degree. \n",
    "You'll need to make a version that takes in an additional parameter, `alpha` and use `sklearn.linear_model.Ridge` to create ridge polynomial regression pipelines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline__unpenalized_linear_regr_with_poly_feats(degree=1):\n",
    "    pipeline = sklearn.pipeline.Pipeline(\n",
    "        steps=[\n",
    "         ('rescaler', sklearn.preprocessing.MinMaxScaler()),\n",
    "         ('poly_transformer', sklearn.preprocessing.PolynomialFeatures(degree=degree, include_bias=False)),\n",
    "         ('regr', sklearn.linear_model.LinearRegression())\n",
    "        ])\n",
    "    \n",
    "    # Return the constructed pipeline\n",
    "    # We can treat it as if it has a 'regression' API\n",
    "    # e.g. a fit and a predict method\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting learned weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access individual steps of the pipeline to extract information, as demonstrated in the blow function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_learned_weights(pipeline, xcolnames_F):\n",
    "    ''' Print the learned parameters of given pipeline.\n",
    "        Note that this function assumes that the pipeline has the named steps \"poly_transformer\" and \"regr\"\n",
    "    '''\n",
    "    my_lin_regr = pipeline.named_steps['regr']\n",
    "\n",
    "    feat_names = pipeline.named_steps['poly_transformer'].get_feature_names_out()\n",
    "    coef_values = my_lin_regr.coef_\n",
    "\n",
    "    print(\"intercept: %.2f\" % (my_lin_regr.intercept_))\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"%9s   %s\" % (\"weight\", \"feature var\"))\n",
    "    for feat, coef in zip(feat_names, coef_values):\n",
    "        print(\"% 9.2f * %s\" % (coef, feat))\n",
    "    \n",
    "    print(\"where \")\n",
    "    for ff, colname in enumerate(xcolnames_F):\n",
    "        print(\"x%d = %s\" % (ff, colname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs135_26s_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
