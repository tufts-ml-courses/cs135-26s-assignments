{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 : Evaluating Binary Classifiers\n",
    "\n",
    "### Instructions\n",
    "\n",
    "The authoritative HW3 instructions are on the course website:\n",
    "\n",
    "http://www.cs.tufts.edu/cs/135/2026s/hw3.html\n",
    "\n",
    "Please report any questions to Piazza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.impute \n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-v0_8') # pretty matplotlib plots\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme('notebook', style='whitegrid', font_scale=1.25)\n",
    "\n",
    "RANDOM_SEED = 68"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cervical Cancer Risk Screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to adjust the path\n",
    "cervical_cancer_risk_factors = pd.read_csv(\"risk_factors_cervical_cancer.csv\")\n",
    "\n",
    "# Remove target variable (biopsy) and other diagnostic tests we're not using\n",
    "X_df = cervical_cancer_risk_factors.drop(columns=[\"Biopsy\"]) #, \"Schiller\", \"Hinselmann\"\n",
    "y = cervical_cancer_risk_factors.Biopsy.to_numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Replace all of the \"?\" with NaN (not a number)\n",
    "X_df = X_df.replace('?', np.nan)\n",
    "# We also should make sure that everything is now being treated as numeric, \n",
    "# since pandas may have decided columns containing \"?\" were strings. \n",
    "X_df = X_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "y = cervical_cancer_risk_factors.Biopsy.to_numpy() \n",
    "\n",
    "# Create a train/validation/test split\n",
    "X_dev, X_test, y_dev, y_test = sklearn.model_selection.train_test_split(\n",
    "    X_df, y, test_size=0.15, random_state=RANDOM_SEED, stratify=y\n",
    ")\n",
    "# Further split the development set into a training and validation set\n",
    "X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(\n",
    "    X_dev, y_dev, test_size=0.33, random_state=RANDOM_SEED, stratify=y_dev\n",
    ")\n",
    "  \n",
    "print(X_dev.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains a significant amount of missing data, which is denoted by \"?\" (we converted them to NaN). \n",
    "\n",
    "This is a common occurrence with questionnaire data, especially in a medical context. Asking patients about topics stigmatized in many cultures such as sexual history, birth control, or drug use can result in high non-response rates due to patients be wary of social stigma. Those tasked with collecting questionnaire data may refuse to ask sensitive questions and simply mark them as missing by default. \n",
    "\n",
    "When collecting and analyzing data, we need to consider context. Are there large social costs to a patient if they answer this question truthfully? Will they be alone with a clinician or around family when asked this question? Are they answering questions out loud, or filling out written form? These factors may have been taken into account for this questionarre, but generally if we are collecting data via questionnaire we want to **design it in partnership with community members** who understand the context to minimize missing data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_counts = X_dev.isnull().sum()\n",
    "missing_percentage = (X_dev.isnull().sum() / len(X_dev)) * 100\n",
    "\n",
    "# Combine into a clean table\n",
    "missing_info = pd.concat([missing_counts, missing_percentage], axis=1, keys=['Total Missing', 'Percent'])\n",
    "print(missing_info.sort_values(by='Percent', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have two columns, `STDs: Time since first diagnosis` and `STDs: Time since last diagnosis` that are missing for over 90% of values in the training set. Let's drop all columns with more than 60% missing data, which would result in these two columns being dropped. Notice that we exclude the testing set from calculating which columns to drop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = X_dev.columns[X_dev.isna().mean() > 0.60].tolist()\n",
    "X_dev = X_dev.drop(columns=cols_to_drop)\n",
    "X_train = X_train.drop(columns=cols_to_drop)\n",
    "X_val = X_val.drop(columns=cols_to_drop)\n",
    "X_test = X_test.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will *impute* the rest of the missing values in the dataset. Strategies for dealing with missing data could be the topic of an entire course, but for this analysis we will use scikit-learn's [KNNImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html). This imputes missing feature values by calculating the mean of the $k$ nearest other instances by euclidean distance. \n",
    "\n",
    "However, imputing this way on the entire dataset before performing a train/test split would result in data leakage, as we would be using information from the test set during training, which could cause us to overestimate how well our trained model generalizes. Instead, we can using `KNNImputer` in a pipeline (along with `MinMaxScaler()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creates a sklearn pipeline for logistic regression with imputation and rescaling steps.\n",
    "C is the inverse regularization strength, smaller values resulting in higher regularization\n",
    "Pass in l1_ratio=0 for L2-regularized logit, and l1_ratio=1 for L1-regularized logit\n",
    "\"\"\"\n",
    "def make_logit_pipeline_knnimpute(C=1.0, k=5):\n",
    "    pipeline = sklearn.pipeline.Pipeline(\n",
    "        steps=[\n",
    "         #('imputer', sklearn.impute.SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "         ('imputer', sklearn.impute.KNNImputer(n_neighbors=k)),\n",
    "         ('rescaler', sklearn.preprocessing.MinMaxScaler()),\n",
    "         ('logit', sklearn.linear_model.LogisticRegression(solver=\"lbfgs\", l1_ratio=0, C=C))\n",
    "        ])\n",
    "    \n",
    "    # Return the constructed pipeline\n",
    "    return pipeline\n",
    "\n",
    "def make_knn_knnimpute(k_model=5, k_impute=5):\n",
    "    pipeline = sklearn.pipeline.Pipeline(\n",
    "        steps=[\n",
    "         #('imputer', sklearn.impute.SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "         ('imputer', sklearn.impute.KNNImputer(n_neighbors=k_impute)),\n",
    "         ('rescaler', sklearn.preprocessing.MinMaxScaler()),\n",
    "         ('knn', sklearn.neighbors.KNeighborsClassifier(n_neighbors=k_model))\n",
    "        ])\n",
    "    \n",
    "    # Return the constructed pipeline\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs135_26s_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
